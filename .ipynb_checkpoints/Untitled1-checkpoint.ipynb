{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.p_utils import read_raster\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def size_filter_func(image_path):\n",
    "    shape = read_raster(image_path)[0].shape\n",
    "    area = shape[0]*shape[1]\n",
    "    if area > 1e6:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "size_filter = lambda images: list(filter(size_filter_func, images))\n",
    "\n",
    "def get_images(bands, year=\"*\", month=\"*\"):\n",
    "    all_images = {\n",
    "        band: glob(f\"../data_source/WHOLE_LONDON_DATASET/*LONDON--{year}-{month}-*--*.{band}.tif\") for band in bands\n",
    "    }\n",
    "    return {k: size_filter(v) for k, v in all_images.items()}\n",
    "\n",
    "def get_image_middle(image):\n",
    "    middle0 = image.shape[0]//2\n",
    "    middle1 = image.shape[1]//2\n",
    "    return middle0, middle1\n",
    "\n",
    "def stack_image_middle(*images):\n",
    "    max_size = np.array([i.shape for i in images]).max(axis=0)\n",
    "    ref0, ref1 = max_size[0]//2, max_size[1]//2\n",
    "    image_stack = []\n",
    "    for image in images:\n",
    "        image0, image1 = get_image_middle(image)\n",
    "        pin0, pin1 = ref0 - image0, ref1 - image1\n",
    "        canvas = np.zeros(max_size)\n",
    "        canvas[pin0:pin0+image.shape[0],pin1:pin1+image.shape[1]] = image\n",
    "        image_stack.append(canvas)\n",
    "    return np.dstack(image_stack)\n",
    "\n",
    "def sample_image(image, tl0, tl1, sample_width=16):\n",
    "    return image[t0:t0+sample_width,t1:t1+sample_width]\n",
    "\n",
    "\n",
    "image_tilt_ref = tilt_dict = {\n",
    "    \"bad\": [\n",
    "        \"2020-04-22--10-58-07\",\n",
    "        \"2020-06-25--10-58-18\",\n",
    "        \"2020-08-12--10-58-33\"\n",
    "    ],\n",
    "    \"good\": [\n",
    "        \"2014-04-15--10-52-21\",\n",
    "        \"2014-07-04--10-52-12\",\n",
    "        \"2020-04-15--10-51-59\",\n",
    "        \"2020-06-02--10-51-54\",\n",
    "        \"2020-07-20--10-52-17\",\n",
    "        \"2020-08-05--10-52-21\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def tilt_correction(image_file_names, image_dict, image_ref = image_tilt_ref):\n",
    "    \n",
    "    for band, fns in image_file_names.items():\n",
    "        for j, fn in enumerate(fns):\n",
    "            if any([d in fn for d in image_ref[\"bad\"]]):\n",
    "                image_dict[band][j] = rotate(image_dict[band][j], -5)\n",
    "            elif any([d in fn for d in image_ref[\"good\"]]):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"{fn} not catalogued\")\n",
    "                \n",
    "    return image_dict\n",
    "\n",
    "\n",
    "def construct_image_dict_from_file_dict(image_files, bands):\n",
    "    images = {band: [read_raster(m)[0] for m in filenames] for band, filenames in image_files.items()}\n",
    "    images = tilt_correction(image_files, images)\n",
    "    stacked_images = {band: stack_image_middle(*imgs) for band, imgs in images.items()}\n",
    "    return stacked_images\n",
    "\n",
    "\n",
    "def construct_image_dict(bands, year=\"*\", month=\"*\"):\n",
    "    image_files = get_images(bands, year, month)\n",
    "    stacked_images = construct_image_dict_from_file_dict(image_files, bands)\n",
    "    return stacked_images, image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "def is_inside_border(sample):\n",
    "    if not any(np.isnan(sample.reshape(-1))) and (0 not in sample.reshape(-1)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "def locate_samples(num_samples, check_band, sample_size, image_dict):\n",
    "    check_image = image_dict[check_band]\n",
    "    samples = []\n",
    "    for n in tqdm(range(num_samples)):\n",
    "        while True:\n",
    "            idx0 = np.random.randint(0, check_image.shape[0]-sample_size)\n",
    "            idx1 = np.random.randint(0, check_image.shape[1]-sample_size)\n",
    "            sample = check_image[idx0:idx0+sample_size,idx1:idx1+sample_size,:]\n",
    "            if is_inside_border(sample):\n",
    "                samples.append([idx0, idx1, sample_size])\n",
    "                break\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BaseSampleDatabase(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dates,\n",
    "        output_dates,\n",
    "        agg_input,\n",
    "        image_input,\n",
    "        agg_output,\n",
    "        sample_info,\n",
    "        image_dict,\n",
    "        filename_dict\n",
    "    ):\n",
    "        self.input_dates=input_dates\n",
    "        self.output_dates=output_dates\n",
    "        self.agg_input=agg_input\n",
    "        self.image_input=image_input\n",
    "        self.agg_output=agg_output\n",
    "        self.sample_info=sample_info\n",
    "        self.image_dict=image_dict\n",
    "        self.filename_dict=filename_dict\n",
    "        \n",
    "        self.previously_notified_list = []\n",
    "        self.seperate_image_dict()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_info)\n",
    "    \n",
    "    @staticmethod\n",
    "    def take_sample(image, sample, aggregate):\n",
    "        sample_image = image[sample[0]:sample[0]+sample[-1],sample[1]:sample[1]+sample[-1],:]\n",
    "        if aggregate:\n",
    "            return np.mean(sample_image)\n",
    "        else:\n",
    "            return np.mean(sample, axis = -1)\n",
    "        \n",
    "    def seperate_image_dict(self):\n",
    "        self.input_image_dict = {band: [] for band in self.image_dict.keys()}\n",
    "        self.output_image_dict = {band: [] for band in self.image_dict.keys()}\n",
    "        \n",
    "        for band, stacked_image in self.image_dict.items():\n",
    "            band_filenames = self.filename_dict[band]\n",
    "            for j, fn in enumerate(band_filenames):\n",
    "                fn = fn.split(\"LONDON--\")[-1].split(\".\")[0]\n",
    "                if fn in self.input_dates:\n",
    "                    self.input_image_dict[band].append(stacked_image[:,:,j])\n",
    "                elif fn in self.output_dates:\n",
    "                    self.output_image_dict[band].append(stacked_image[:,:,j]) \n",
    "                else:\n",
    "                    if fn not in self.previously_notified_list:\n",
    "                        self.previously_notified_list.append(fn)\n",
    "                        print(f\"{fn} not in input/output list, not used!\")\n",
    "            self.input_image_dict[band] = np.dstack(self.input_image_dict[band])\n",
    "            self.output_image_dict[band] = np.dstack(self.output_image_dict[band])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample_info = self.sample_info[idx]\n",
    "        res = {\"sample-coords\": sample_info}\n",
    "        \n",
    "        for band in self.agg_input:\n",
    "            res[f\"{band}-in\"] = self.take_sample(self.input_image_dict[band], sample_info, True)\n",
    "        for band in self.agg_output:\n",
    "            res[f\"{band}-out\"] = self.take_sample(self.output_image_dict[band], sample_info, True)\n",
    "        for band in self.image_input:\n",
    "            res[f\"{band}-in\"] = self.take_sample(self.input_image_dict[band], sample_info, False)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-bc53177ce0fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mUI_BAND\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"UI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstacked_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_image_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_bands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msample_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocate_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_band\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECK_BAND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacked_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e98414bdee17>\u001b[0m in \u001b[0;36mconstruct_image_dict\u001b[0;34m(bands, year, month)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconstruct_image_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mstacked_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_image_dict_from_file_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstacked_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e98414bdee17>\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(bands, year, month)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mband\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../data_source/WHOLE_LONDON_DATASET/*LONDON--{year}-{month}-*--*.{band}.tif\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     }\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_image_middle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e98414bdee17>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mband\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../data_source/WHOLE_LONDON_DATASET/*LONDON--{year}-{month}-*--*.{band}.tif\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mband\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     }\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_image_middle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e98414bdee17>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msize_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_filter_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e98414bdee17>\u001b[0m in \u001b[0;36msize_filter_func\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msize_filter_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratches/mario/hw501/satellite-cGAN/pipelines/p_utils.py\u001b[0m in \u001b[0;36mread_raster\u001b[0;34m(path, remove_zero)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mraster_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mraster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mremove_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mraster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CHECK_BAND = \"B10\"\n",
    "LST_BAND = \"LST\"\n",
    "NDVI_BAND = \"NDVI\"\n",
    "NDBI_BAND = \"NDBI\"\n",
    "NDWI_BAND = \"NDWI\"\n",
    "UI_BAND = \"UI\"\n",
    "\n",
    "stacked_images, image_files = construct_image_dict(bands=all_bands, year=\"*\", month=\"*\")\n",
    "sample_info = locate_samples(num_samples=500, check_band=CHECK_BAND, sample_size=16, image_dict=stacked_images)\n",
    "\n",
    "dataset = BaseSampleDatabase(        \n",
    "    input_dates=[\"2014-07-04--10-52-12\",\"2014-04-15--10-52-21\"],\n",
    "    output_dates = [\"2020-08-05--10-52-21\",\"2020-07-20--10-52-17\",\"2020-06-02--10-51-54\",\"2020-04-22--10-58-07\",\"2020-06-25--10-58-18\",\"2020-08-12--10-58-33\",\"2020-04-15--10-51-59\"],\n",
    "    agg_input=[NDVI_BAND, NDBI_BAND, NDWI_BAND, LST_BAND, UI_BAND],\n",
    "    image_input=[],\n",
    "    agg_output=[LST_BAND],\n",
    "    sample_info=sample_info,\n",
    "    image_dict=stacked_images,\n",
    "    filename_dict=image_files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningOperation:\n",
    "    \n",
    "    def __init__(self, dataset, learner, input_vars, output_vars, **kwargs):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.learner = learner\n",
    "        self.input_vars = input_vars\n",
    "        self.output_vars = output_vars\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "        unclaimed_vars = set(input_vars + output_vars) - set(dataset[0])\n",
    "        if unclaimed_vars:\n",
    "            raise ValueError(f\"{unclaimed_vars} not in input or output vars\")\n",
    "    \n",
    "    def generate_batch(self):\n",
    "        pass\n",
    "        \n",
    "    def step(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, var_dict): \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class LinearRegressionOperation(LearningOperation):\n",
    "    \n",
    "    def __init__(self, dataset, input_vars, output_vars):\n",
    "        learner = LinearRegression()\n",
    "        super().__init__(dataset, learner, input_vars, output_vars)\n",
    "        \n",
    "    def generate_batch(self):\n",
    "        dataset_dicts = [d for d in self.dataset]\n",
    "        X_array = np.array([[d[iv] for iv in self.input_vars] for d in dataset_dicts])\n",
    "        y_array = np.array([[d[ov] for ov in self.output_vars] for d in dataset_dicts])\n",
    "        return X_array, y_array\n",
    "        \n",
    "    def step(self):\n",
    "        self.learner.fit(*self.generate_batch())\n",
    "        \n",
    "    def train_score(self):\n",
    "        return self.learner.score(*self.generate_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3343373312734619"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lro = LinearRegressionOperation(\n",
    "    dataset, input_vars = [\"B2-in\", \"B3-in\", \"B4-in\", \"B10-in\"], output_vars = [\"B10-out\"]\n",
    ")\n",
    "\n",
    "lro.step()\n",
    "lro.train_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_image_tilt_ref = tilt_dict = {\"bad\": [\"2018-05-19--10-57-32\",\"2019-04-20--10-58-00\",\"2017-06-17--10-58-17\",\"2017-06-01--10-58-10\",\"2018-07-06--10-57-40\",\"2018-08-07--10-57-56\",\"2016-08-17--10-58-39\",\"2019-08-26--10-58-45\",\"2019-07-25--10-58-34\"],\"good\": [\"2017-05-25--10-51-56\",\"2018-06-29--10-51-26\",\"2017-06-10--10-52-04\",\"2018-07-15--10-51-33\",\"2018-07-31--10-51-41\",\"2016-04-20--10-51-56\",\"2019-05-15--10-51-58\",\"2017-08-13--10-52-26\",\"2016-08-26--10-52-32\"]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
